---
output:
  pdf_document: default
  html_document: default
---
Within this project, I would like to explore the  CoinGecko API and the package "geckor" in R.
Then I would collect the current and historical cryptocurrency market data for a coin using the public 'CoinGecko' API and do a Arima forecast.

```{r setup, include=FALSE, fig.width=8, fig.height=8}
library(geckor)
library(dplyr)
library(tseries)
library(forecast)
library(Metrics)
library(ggplot2)
```
# Data preparation

Let's use dogecoin as an example here. First, I want to obtain historical data for dogecoin.
The function "coin_history" can retrieve coin-specific market data for the last n days. If  open-high-low-close price data is needed, use function "coin_history_ohlc" instead.


```{r}
r <- coin_history(coin_id = "dogecoin", vs_currency = "usd", days = "max")
r
```

Since we only need date and price from obtained data, I save them in a dataframe
and convert it to timeserie formatt for later use. So now df has all daily market price
for dogecoin. Below is last 7 days price in ts object. Since each coin has different start
date in coin market, we need to record the first date in df.

```{r}
var <- c("timestamp", "price")
df <- r[var]
df <- df[c(1:nrow(df) - 1),]
date <- df$timestamp
start_date <- date[1]
dayOfYear <- as.numeric(format(as.Date(start_date),"%j"))
year <- as.numeric(format(as.Date(start_date),"%Y"))
df <- ts(df$price, start = c(year, dayOfYear), frequency = 365)
tail(df,7)
```

Now, let's define the training and test period. I will use the last 7 days as 
test set and all other historical data as training set.

```{r}
train_end <-  length(df) - 7
test_start <-  length(df) - 6

df_train <-  ts(df[c(1:train_end)])
df_test <-  ts(df[c(test_start:length(df))])
```

We now need to check the stationary of our data.  We can do that with the Augmented Dickey-Fuller Test.

H0: The time series is non-stationary. 
H1: The time series is stationary.
Since the p-value is not less than .05, we fail to reject the null hypothesis.
This means the time series is non-stationary. Our data is depend on the time at 
which the series is observed.

```{r}
adf.test(df)
```
# Time series modeling
## ARIMA models which aim to describe the autocorrelations in the data.
We will run the auto.arima function on our training data, which will help us to forecast
next 7 days market price and their prediction intervals. 

```{r}
fit_arima <- auto.arima(df_train)
fcast_arima <- forecast(fit_arima, h = 7, level = 95)

fcast_arima
```

Now, let's get the Metrics MAPE which is used to judge the performance of the model.It gives the average deviation between the forecast value and actual values.

```{r}
mape_arima <- mape(df_test,as.numeric(fcast_arima$mean))*100
mape_arima
```
## Exponential smoothing models (ETS) are based on a description of the trend and seasonality in the data.
```{r}
fit_ets <- ets(df_train)
fcast_ets <- forecast(fit_ets, h = 7, level = 95)

mape_ets <- mape(df_test,as.numeric(fcast_ets$mean))*100
mape_ets
```

let's create a table of predicted price, actual price and their MAPE at last row. This will help 
us to do comparison.

```{r}
result <- cbind(df_test,as.numeric(fcast_arima$mean),as.numeric(fcast_ets$mean))
result <- rbind(result,c(0,mape_arima,mape_ets))
colnames(result) <- c("Actual","ARIMA","ETS")
round(result,4)
```



Lastly, plot the historical price for bitcion, certainly the price has been jumping insane
last few years.

```{r}
autoplot(fcast_arima) + (labs(y = "Price", x = "Days"))
```